/**
 * UPLOAD SERVICE - BLOB-FIRST APPROACH
 *
 * This service implements the new blob-first upload flow:
 * 1. Upload file to blob storage (Vercel Blob, AWS S3, etc.)
 * 2. Get blob URL from storage provider
 * 3. Call POST /api/memories with blob URL and metadata
 *
 * This replaces the old approach of sending files directly to backend endpoints.
 */

import { type StorageBackend } from '@/lib/storage';
import { icpUploadService } from '@/services/icp-upload';
import { upload as blobUpload } from '@vercel/blob/client';
// import type { UploadStorage } from "@/hooks/use-upload-storage"; // Unused

interface UploadResponse {
  success: boolean;
  data: {
    id: string;
    type: string;
    title: string;
    description: string;
    fileCreatedAt: string;
    isPublic: boolean;
    parentFolderId: string | null;
    tags: string[];
    recipients: string[];
    unlockDate: string | null;
    metadata: Record<string, unknown>;
    createdAt: string;
    assets: Array<{
      id: string;
      assetType: string;
      url: string;
      bytes: number;
      mimeType: string;
      storageBackend: string;
      storageKey: string;
    }>;
  };
}

type UploadMode = 'files' | 'folder';

/**
 * Get memory type from file extension
 */
function getMemoryTypeFromFile(file: File): 'image' | 'video' | 'document' | 'note' | 'audio' {
  const extension = file.name.split('.').pop()?.toLowerCase();

  if (!extension) return 'document';

  const imageExtensions = ['jpg', 'jpeg', 'png', 'gif', 'webp', 'svg', 'bmp', 'tiff'];
  const videoExtensions = ['mp4', 'avi', 'mov', 'wmv', 'flv', 'webm', 'mkv'];
  const audioExtensions = ['mp3', 'wav', 'flac', 'aac', 'ogg', 'm4a'];

  if (imageExtensions.includes(extension)) return 'image';
  if (videoExtensions.includes(extension)) return 'video';
  if (audioExtensions.includes(extension)) return 'audio';

  return 'document';
}

/**
 * Upload file to ICP backend using real ICP upload service
 * This bypasses the normal blob-first flow and uploads directly to ICP canister
 *
 * NOTE: For ICP users, isOnboarding is not used because:
 * - ICP canister interactions ALWAYS require Internet Identity authentication
 * - Even "onboarding" users must be authenticated to interact with ICP
 * - The ICP canister itself handles user/memory creation, not our backend
 * - This is different from Neon users where onboarding creates temporary users without auth
 */
async function uploadToICPBackend(file: File): Promise<UploadResponse> {
  console.log(`üöÄ Starting ICP backend upload for ${file.name}...`);

  try {
    // Get proper upload storage from the upload intent API
    const uploadStorageResponse = await fetch('/api/upload/intent', {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({
        storagePreference: { preferred: 'icp-canister' },
      }),
    });

    if (!uploadStorageResponse.ok) {
      throw new Error(`Failed to get upload storage: ${uploadStorageResponse.status}`);
    }

    const { uploadStorage } = await uploadStorageResponse.json();

    if (uploadStorage.chosen_storage !== 'icp-canister') {
      throw new Error('Expected ICP canister storage but got different backend');
    }

    // Upload to ICP canister using the real service
    const icpResult = await icpUploadService.uploadFile(file, uploadStorage, progress => {
      console.log(`üì§ ICP Upload progress: ${progress.percentage}%`);
    });

    console.log(`‚úÖ ICP upload successful: ${icpResult.memoryId}`);

    // Verify upload (best-effort, don't block on failure)
    try {
      await fetch('/api/upload/verify', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({
          app_memory_id: icpResult.memoryId,
          backend: 'icp-canister',
          idem: uploadStorage.idem,
          checksum_sha256: icpResult.checksum_sha256,
          size: icpResult.size,
          remote_id: icpResult.remote_id,
        }),
      });
    } catch (verifyError) {
      console.warn('‚ö†Ô∏è Upload verification failed (non-blocking):', verifyError);
    }

    // Convert ICP result to expected format
    return {
      success: true,
      data: {
        id: icpResult.memoryId,
        type: getMemoryTypeFromFile(file),
        title: file.name.split('.')[0] || 'Untitled',
        description: '',
        fileCreatedAt: new Date().toISOString(),
        isPublic: false,
        parentFolderId: null,
        tags: [],
        recipients: [],
        unlockDate: null,
        metadata: {},
        createdAt: new Date().toISOString(),
        assets: [
          {
            id: `asset-${icpResult.memoryId}`,
            assetType: 'original',
            url: `icp://${icpResult.memoryId}`, // ICP URL format
            bytes: icpResult.size,
            mimeType: file.type,
            storageBackend: 'icp',
            storageKey: icpResult.remote_id,
          },
        ],
      },
    };
  } catch (error) {
    console.error('‚ùå ICP backend upload failed:', error);
    throw error;
  }
}

/**
 * Upload a file using the new blob-first approach
 */
export const uploadFile = async (
  file: File,
  isOnboarding: boolean,
  existingUserId?: string,
  mode: UploadMode = 'files',
  storageBackend: StorageBackend | StorageBackend[] = 'vercel_blob',
  userStoragePreference?: 'neon' | 'icp' | 'dual'
): Promise<UploadResponse> => {
  console.log(`üöÄ Starting upload for ${file.name}...`);
  console.log(`üîç Upload parameters:`, {
    fileName: file.name,
    fileSize: file.size,
    fileType: file.type,
    isOnboarding,
    existingUserId,
    mode,
    storageBackend,
    userStoragePreference,
  });

  try {
    // Check if user prefers ICP-only backend
    if (userStoragePreference === 'icp') {
      console.log(`üîó User prefers ICP backend, routing to ICP canister...`);
      // NOTE: For ICP users, isOnboarding is ignored because ICP always requires Internet Identity auth
      // Even "onboarding" users must authenticate with II to interact with ICP canister
      return await uploadToICPBackend(file);
    }

    // Simplified upload decision matrix - use client upload for all files
    const fileSizeMB = file.size / (1024 * 1024);
    const isImage = file.type.startsWith('image/');

    console.log(`üìä FILE ANALYSIS:`, {
      fileName: file.name,
      fileSizeBytes: file.size,
      fileSizeMB: fileSizeMB.toFixed(2),
      fileType: file.type,
      isImage,
      chosenPath: 'CLIENT_UPLOAD_PATH', // All files now use client upload
    });

    // All files now use the client upload flow (grant-based upload)
    // This provides consistent behavior, better progress tracking, and handles all file sizes
    console.log(`‚òÅÔ∏è Using client upload flow for ${file.name} (${fileSizeMB.toFixed(1)}MB)...`);
    return await uploadFileToBlob(file, isOnboarding, existingUserId, mode);
  } catch (error) {
    console.error('‚ùå Upload failed:', error);
    throw error;
  }
};

/**
 * Upload files using client-side upload flow with Vercel Blob
 * This handles all file sizes using the grant-based upload approach
 */
async function uploadFileToBlob(
  file: File,
  isOnboarding: boolean,
  existingUserId?: string,
  mode: UploadMode = 'files'
): Promise<UploadResponse> {
  console.log(`‚òÅÔ∏è Using client-side upload flow for: ${file.name}`);

  // Use new client-side upload flow with our grant endpoint
  const clientPayloadData = {
    isOnboarding,
    mode,
    filename: file.name,
    existingUserId,
    // Add any other context needed on the server side
  };

  console.log('üì§ Sending client payload:', clientPayloadData);

  const blob = await blobUpload(file.name, file, {
    access: 'public',
    handleUploadUrl: '/api/memories/grant', // Use our corrected grant endpoint
    multipart: true, // chunked + parallel + retries for large files
    clientPayload: JSON.stringify(clientPayloadData),
    onUploadProgress: ev => {
      // Hook into UI progress tracking
      if (typeof window !== 'undefined') {
        console.log(`üì§ Upload progress: ${ev.percentage ?? 0}% for ${file.name}`);
        // TODO: Dispatch progress to a store or UI component
        // dispatch({ type: 'UPLOAD_PROGRESS', file: file.name, percentage: ev.percentage });
      }
    },
  });

  console.log(`‚úÖ Client-side upload successful: ${blob.url}`);

  // WORKAROUND: Since onUploadCompleted callback doesn't work on localhost,
  // we need to create the memory record client-side
  try {
    console.log('üîß Creating memory record client-side (localhost workaround)...');

    const memoryResponse = await fetch('/api/memories', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({
        blobUrl: blob.url,
        filename: file.name,
        contentType: file.type,
        size: file.size,
        pathname: blob.pathname,
        isOnboarding,
        mode,
        ...(existingUserId && { userId: existingUserId }), // Only include userId if it exists
      }),
    });

    if (!memoryResponse.ok) {
      throw new Error(`Failed to create memory: ${memoryResponse.statusText}`);
    }

    const memoryData = await memoryResponse.json();
    console.log('‚úÖ Memory created successfully:', memoryData);

    return {
      success: true,
      data: memoryData.data,
    };
  } catch (error) {
    console.error('‚ùå Failed to create memory record:', error);

    // Fallback: return the blob info even if memory creation failed
    // This allows the upload to appear successful, but the file won't show in dashboard
    return {
      success: true,
      data: {
        id: 'temp-id', // Temporary ID - file won't appear in dashboard
        type: getMemoryTypeFromFile(file),
        title: file.name.split('.')[0] || 'Untitled',
        description: '',
        fileCreatedAt: new Date().toISOString(),
        isPublic: false,
        parentFolderId: null,
        tags: [],
        recipients: [],
        unlockDate: null,
        metadata: {},
        createdAt: new Date().toISOString(),
        assets: [
          {
            id: 'temp-asset-id',
            assetType: 'original',
            url: blob.url,
            bytes: file.size,
            mimeType: file.type,
            storageBackend: 'vercel_blob',
            storageKey: blob.pathname,
          },
        ],
      },
    };
  }
}

/**
 * Upload multiple files (folder upload) using blob-first approach
 */
export const uploadFiles = async (
  files: File[],
  isOnboarding: boolean,
  existingUserId?: string,
  mode: UploadMode = 'folder',
  storageBackend: StorageBackend | StorageBackend[] = 'vercel_blob',
  userStoragePreference?: 'neon' | 'icp' | 'dual'
): Promise<UploadResponse[]> => {
  console.log(`üöÄ Starting folder upload for ${files.length} files...`);

  const uploadPromises = files.map((file, index) => {
    console.log(`üì§ Uploading file ${index + 1}/${files.length}: ${file.name}`);
    return uploadFile(file, isOnboarding, existingUserId, mode, storageBackend, userStoragePreference);
  });

  try {
    const results = await Promise.allSettled(uploadPromises);

    const successful = results
      .filter((result): result is PromiseFulfilledResult<UploadResponse> => result.status === 'fulfilled')
      .map(result => result.value);

    const failed = results
      .filter((result): result is PromiseRejectedResult => result.status === 'rejected')
      .map((result, index) => ({
        file: files[index].name,
        error: result.reason.message,
      }));

    if (failed.length > 0) {
      console.warn(`‚ö†Ô∏è ${failed.length} files failed to upload:`, failed);
    }

    console.log(`‚úÖ Folder upload completed: ${successful.length}/${files.length} successful`);
    return successful;
  } catch (error) {
    console.error('‚ùå Folder upload failed:', error);
    throw error;
  }
};
